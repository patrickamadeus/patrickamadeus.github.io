---
layout: homepage
---

## About Me

- I am a **PhD student** at [MBZUAI](https://mbzuai.ac.ae/) ğŸ¤–, where I focus on multimodal NLP topics, particularly vision-language interaction. I also work on vision-language alignment, unified (any) multimodal models, and large-scale evaluations.

- Previously, I was a **Research Engineer** at SMU ğŸ‡¸ğŸ‡¬ working at the intersection of multilingual and multimodal interpretation under Prof.[ Chong-Wah Ngo](https://scholar.google.com/citations?user=HM39HrUAAAAJ&hl=en). I earned my bachelorâ€™s degree in CS from Institut Teknologi Bandung, where I worked under Prof.[Ayu Purwarianti](https://scholar.google.com/citations?user=8jUro_cAAAAJ&hl=en) on explainable multimodal synthetic data generation. In addition to research, I also do AI engineering for various use cases. You can see my other experiences [here](https://www.linkedin.com/in/patrickamadeus/).

- Further, I plan to specialize my studies in developing methods to better align different modalities, with the goal of mitigating modality imbalance, especially in the avenue of unified multimodal models.

## Research Interests

During my studies and prior experience, I have often worked on topics including, but not limited to, the following:
1. **Multimodal Imbalance:** I believe that imbalanced learning is a significant bottleneck that prevents us from obtaining reliable multimodal models, as modality shortcuts and biases can harm both performance and the objectivity of evaluation. My work focuses on discovering its root causes and exploring methods to better align models to prevent such issues.
2. **LLM/VLM Alignment:** I also work on both architectural and non-architectural adaptations (knowledge enrichment, data reformulation, RL) to address above issues and/or improve multimodal language modeling in general.
3. **Large-Scale Evaluations:** I often question model robustness in scenarios with varying resource levels; however, probing this requires designing both broad and specific evaluation coverage. My work in this area aims to design benchmarks that assess the inclusivity of multimodal models, specifically by addressing concept underrepresentation through targeted data curation in multilingual and multicultural domains.

## Updates

- **[Oct. 2025]** [Entropy2Vec](https://arxiv.org/abs/2509.05060) got accepted into MRL Workshop @ EMNLP 2025 ğŸŒğŸ‡¨ğŸ‡³!
- **[July 2025]** [Seeing Culture Benchmark](https://seeingculture-benchmark.github.io) is accepted to EMNLP 2025 ğŸ‡¨ğŸ‡³! On to the next one with SMU Multimedia team ğŸ’ª
- **[May. 2025]** [DataRubrics](https://arxiv.org/abs/2506.01789) is now on arXiv! We propose a unified scorecard to evaluate data quality on multi-faceted metrics.
- **[Apr. 2025]** [WorldCuisines](https://worldcuisines.github.io/) receives Best Theme Paper award at NAACL 2025! ğŸ‰ğŸŒğŸ½ï¸  
- **[Mar. 2025]** Admitted to the Fall 2025 cohort of the **MBZUAI PhD program in NLP**! ğŸ“š
- **[Jan. 2025]** [WorldCuisines](https://worldcuisines.github.io/) and *ProxyLM* are accepted to NAACL 2025 ğŸ‡ºğŸ‡¸ ğŸ–ï¸  
- **[Nov. 2024]** My first first-author [paper](https://arxiv.org/abs/2409.14785), a VL synthetic data generation framework, is accepted to COLING 2025 ğŸ‰  
- **[Oct. 2024]** [WorldCuisines](https://worldcuisines.github.io/), the largest multicultural VL food benchmark, is released. Honored to co-lead the project ğŸ¥˜  
- **[Sep. 2024]** [SEACrowd](https://arxiv.org/abs/2406.10118) is accepted to EMNLP 2024! ğŸ‡ºğŸ‡¸

{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}
